---
title: "Exploratory Data Analysis with acledR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Exploratory Data Analysis with acledR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning=F, message=F,
  cache = F
)
```

```{r setup, echo=F}
library(acledR)
library(dplyr)
library(tidyr)
```


The data analysis family of functions can assist you in carrying exploratory data analysis of ACLED data. We developed these functions taking into consideration the use cases of our data, and some of the analysis that we often require internally. 

These functions attempt to speed-up your exploratory data analysis, however, you are highly encouraged to get familiar with our documentation to properly interpret the results from these functions. 

At this time, `acledR` offers three functions aimed at exploratory data analysis:

1.    `acled_generate_counts()` - Event/fatalities counts

2.    `acled_generate_movers()` - Moving statistics of event counts

3.    `acled_actor_concentration`  -  Actor concentration


# Generating counts of ACLED events - `acled_generate_counts()`

```{r, echo=FALSE, message= FALSE}
library(acledR)
acled_access(email = "acledexamples@gmail.com", key = "M3PWwg3DIdhHMuDiilp5") #  This is an example, you will need to input your credentials.
df_sa <- acled_api(regions = c("South America"),
                   start_date = "2022-01-01",
                   end_date = "2022-04-30",
                   monadic = F,
                   prompt=F)
```

The `acled_generate_counts()` function creates event counts by event type, spacial and temporal units of analysis. 

The required arguments are:

```{r function_description, eval = FALSE}
acled_generate_counts(
  data,
  unit_id,
  time_id,
  time_target,
  event_type = NULL
)
```

Arguments:
-   `data` is ACLED event-level data (e.g, ACLED's dyadic dataframe), 
-   `unit_id` is the spatial unit of analysis (e.g., *country*, *admin1*, *region*), 
-   `time_id` is the temporal unit (i.e., *event_date*), and 
-   `time_target` is the temporal unit of aggregation (e.g., week, month, year). 
-   `event_type` - Use in case of wanting to filter events for *event_types*

**Note**: ACLED's data collection does not follow a Monday-Sunday week, but instead a Saturday-Friday week. This function follows the same approach - if `time_target = week`, ACLED's week (starting on Saturday) is used.

### Time in `acled_generate_counts`

`acled_generate_counts` was created so that users could get event counts across different spatial and temporal units in a simple manner. When it comes to temporal units, you can utilize three options:
-   year (e.g.`time_id="year"`)
-   month (e.g. `time_id = "month"`)
-   week (e.g. `time_id = "day"`)

You can generate event counts at the country-week level:

```{r}
df_sa_agg_weekly <-acled_generate_counts(df_sa,
                                   unit_id = "country", 
                                   time_id = "event_date",
                                   time_target = "week")
```

This returns a tibble with columns for each event type in the data, as well as a column for the total events:

```{r}
df_sa_agg_weekly %>% 
  head() %>% 
  kableExtra::kable()
```

You can also limit the request to certain *event_types*. For example, you might only want "Protests" and "Riots" events:

```{r}
df_sa_agg_weekly_pv <-
  df_sa %>% 
  acled_generate_counts(., unit_id = "country", 
                  time_id = "event_date",
                  time_target = "week",
                  event_type = c('Protests', 'Riots')) 
```

Now the object only retains the requested event type and the total (in the new *total_events* column) corresponds to these types only:

```{r}
df_sa_agg_weekly %>% 
  head() %>% 
  kableExtra::kable()
```

If instead, you wanted "Riots" counts by month rather than week, we would simply swap `time_target = week` to `time_target = month`:

```{r}
df_sa_agg_monthly_riots <-
  df_sa %>% 
    acled_generate_counts(., unit_id = "country", 
                  time_id = "event_date",
                  time_target = "month",
                  event_type = "Riots")
```

# Generate moving statistics - `generate_movers`

While `acled_generate_counts()` generates event counts, `acled_generate_movers()`  generates __moving statistics__ of ACLED event counts - i.e. the results of `acled_generate_counts()`. Moving statistics summarize the variation in event counts over a designated period of time. A common example would be a __moving average__, which would represent the average number of events over a specified period of time until most present observation. 

The required parameters are as follows:

```{r, eval = F}
acled_generate_movers(
  data,
  var,
  unit_id,
  time_id,
  slide_funs,
  slide_periods
)
```

-   `data` is event count data from ACLED, i.e. the result of `acled_generate_counts`,

-   `unit_id` is the spatial unit of analysis (e.g., *country*, *admin1*, *region*), 

-   `time_id` is the temporal unit (e.g., week, month, year), 

-   `slide_funs` are the requested moving statistics (e.g., __mean__, __sd__, __median__, __min__, __max__),

-   `slide_periods` are the number of temporal units over which to calculate the moving statistics. 

**Notes:** The `unit_id` and `time_id` must be existing columns in your event count dataframe.

## Example - `acled_generate_counts()` & `acled_generate_movers()`

As an initial example, imagine you wanted to explore the data from "India" since 2018. 

First, pull ACLED data for "India" since 2018 using the `acled_api()` function:

```{r}
library(acledR)

acled_access(email = "acledexamples@gmail.com", key = "M3PWwg3DIdhHMuDiilp5") #  This is an example, you will need to input your credentials.
df_india <- acled_api(countries = "India",
                   start_date = "2018-01-01",
                   end_date = "2022-04-30",
                   monadic = F,
                   prompt=F,
                   acled_access = T)
```

Next, aggregate to event counts per month using the `acled_generate_counts()` function:
```{r}
df_india_agg <-
  df_india %>% 
  acled_generate_counts(., 
                  unit_id = "country", 
                  time_id = "event_date",
                  time_target = "month")
```

You now have a tibble of ACLED event counts by month for each event type, as well the sum across event types:

```{r}
df_india_agg %>%
  dplyr::glimpse()
```

With these event counts, you can use `acled_generate_movers()` to calculate moving statistics out of your total counts. Next, create a new object for the __moving average__ of `total_events` over the last 3 months:

```{r}
df_india_agg_movers <- 
  acled_generate_movers(data = df_india_agg,
                  var = "total_events",
                  unit_id = "country",
                  time_id = "event_month",
                  slide_funs = "mean",
                  slide_periods = 3)
```

You now have a new column for the requested __moving average__: `total_events_moving_mean_3`. Take a look at the first few rows of our new tibble:

```{r}
df_india_agg_movers %>% 
  dplyr::select(country, 
                event_month, 
                total_events, 
                total_events_moving_mean_3)
```

Note that the first 3 months for `total_events_moving_mean_3` are missing. This is because there has not been enough elapsed time in the sample to calculate a complete moving statistic of the requested temporal length (in our case, 3 months). This default behavior can be turned off by setting `complete = F` in the `acled_generate_movers()` function. 

To see how this would change the returned values, try the following:

```{r}
acled_generate_movers(data = df_india_agg,
                  var = "total_events",
                  unit_id = "country",
                  time_id = "event_month",
                  slide_funs = "mean",
                  slide_periods = 3,
                  complete = F) %>% 
  dplyr::select(country, event_month, total_events, 
         total_events_moving_mean_3)
```

Here, the first period returns `NaN` values, while the second period simply fills the first observed value. By the fourth period, the moving averages for the default `complete = T` and `complete = F` versions are the same, as both are calculated moving statistics over a 3 month period. 

Sticking with the default `complete = T` version, we can quickly visualize the trend in event counts over time with `ggplot2`:

```{r, fig.width=7, fig.height=4.5}
library(ggplot2)


df_india_agg_movers %>% 
  
  ggplot() +
  geom_line(aes(x = event_month, y = total_events,
                linetype = "Total events")) +
  geom_line(aes(x = event_month, y = total_events_moving_mean_3,
                linetype = "Moving average (3 months)")) +
  scale_linetype_manual(values = c(3, 1),
                        guide = guide_legend(title = NULL)) +
  theme_light() +
  theme(legend.position = c(0.8, 0.885),
        legend.background = element_rect(color = "gray90"),
        panel.grid = element_blank())

```

# Finding actor concentration -  `acled_actor_concentration()`

The `acled_actor_concentration()` functions extracts the degree of actor concentration in a given data set. Concentration, in statistical terms, refers to the degree by which a measure (in our case, number of events) is dominated by a few entities within a dataset or population. To calculate actor concentration, `acled_actor_concentration()` can utilize two approaches: __Inverse Simpson Index__ or __Herfindahl-Hirschman Index__. Both approaches take different routes to calculate and express these concentration, but both are equally valuable for analysis.

`acled_actor_concentration()` is set-up as follows:

```{r, eval=F}
acled_actor_concentration(events, 
                          method = "Effective actors", 
                          acled_dataframe = T)
```

Arguments:
-   `events` is an ACLED dyadic dataframe (i.e. the result from an `acled_api()` call) or a vector of event/fatalities counts per actor. The required object type of events depends on `acled_dataframe`. 
-   If `acled_dataframe = T` then the function expects ACLED's dyadic dataframe (default behavior), otherwise if `acled_dataframe = F` it expects a vector of event/fatalities counts per actor

-   `method` is the desired methodological approach to calculate concentration indices, either __Inverse Simpson Index__ or __Hertindahl-Hirscham Index__. These are described below:

  -   `method="Effective actors"`: Utilizes the __Inverse Simpson Index__ (also known as the __Reciprocal Simpson Index__) to calculate the number of effective actors by measuring how evenly events/fatalities are distributed across actors. Take a vector where the total number of events across all actors is $N$, and the total counts of each actor is $z_1$, then the number of effective actors ($D$) is $$
    D=1-(∑z_i​(z_i​−1))​/N(N-1)
    $$ The minimum is 1 (least diverse), and the maximum is the total number of actors (perfectly diverse).
  -   `method="Concentration"`: Utilizes the __Herfindahl-Hirschman Index__ to estimate the concentration of actors in a given data set. In a data set where the presence of a given actor is understood as $MS$, and the actor is understood as $i$. The concentration is the sum of the presence (MS) of each given actor (i) elevated by 2, or $$HHI=MS^2_1+MS^2_2+MS^2_3+MS^2_4+...+MS^2_i$$. Because we utilize the presence of a given actors represented in decimals rather than whole numbers (cf. [US DOJ's Horizontal Merger Guidelines (08/19/2019)](https://www.justice.gov/atr/horizontal-merger-guidelines-08192010)) Results range from 0 to 1, where 1 represents a monopoly of a given actor in the environment, and 0.1 represents as a very competitively diverse environment.

Users can utilize these metrics to better understand the distribution and dominance of actors within a data set. In greater terms, the two metrics provide the same information, however, how the output is represented differently. In the __Inverse Simpson Index__ we get the results in a scale from 1 to the nominal maximum number of actors, hence, it directly tells us how many effective actors we have in the dataset. The __Herfindahl-Hirschmanns Index__, shows us the level of concentration in the dataset in a scale from 0 to 1, where the closer we get to 1, the less diverse the dataset becomes, and the closer to 0, the more diverse it becomes. They both provide measures of diversity and concentration, expressed in different terms.

### Example - `acled_actor_concentration()`

```{r gec_css, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE, message = FALSE,
  cache = FALSE
)
```

In this example, you will aim to better understand the concentration of actors in the indian dataset we explored in the example above.

```{r}
df_india %>%
  head(3)
```

Because your dataset is ACLED's dyadic dataframe, you can directly feed it into our `acled_actor_concentration()` function. In this case, `method='Effective actors'`, so you can explore how the __Inverse Simpson Index__ is represented. 
```{r}
isi_df_india <- acled_actor_concentration(df_india, method = "Effective actors")

print(isi_df_india)
```

The result from the function is a new dataframe with three columns, *eff_actors*, *actors*, and *avg_events*. Interestingly, while there are 1679 actors, there are only 9.33 effective actors. We can manually calculate the distribution of events across actors to better ilustrate this. 

```{r, message=FALSE,warning=FALSE, fig.width=5}

long_form_df_india <- df_india %>%
  acled_transform() %>%
  group_by(actor) %>%
  summarise(events = n()) %>% 
  filter(!is.na(actor)) %>%
  dplyr::arrange(-events) %>%
  head(20)

ggplot(long_form_df_india, aes(x = events, y = stats::reorder(actor, events))) +
  geom_bar(stat="identity", fill = "#5F9ED1") +
  geom_text(aes(label=events), vjust=1, size=2.5, color = "black")+
  labs(y = "Actors",
       x = "Number of events",
       title = "Number of events by actor")
```

As we can observe, our dataset is indeed dominated by a couple of actors. From "Protesters (India)" to "Women (India)", there is a fairly heavy distribution. 

Now, run the same function but changing the method to `method="Concentration"`.

```{r}
hhi_df_india <- acled_actor_concentration(df_india, method = "Concentration")

print(hhi_df_india)
```
When using the __Herfindahl-Hirschmanns Index__, we can see that while we only have 9.61 effective actors, out of 1678, the dataset is still fairly diverse. That is because of the number of actors we have, and the number of events these actors have show that there is a fairly diverse number of actors in the dataset. This may sound contradicting when considering the number of effective actors, but this method heavily rewards actors with at least 1 event. 

To illustrate the difference, take the following example: 

```{r}

df <- data.frame(actors=c("actor1", "actor2", "actor3"),
                 events=c(8,1,1))

print(acled_actor_concentration(df$events, method = "Concentration", acled_dataframe = F)$concentration)
print(acled_actor_concentration(df$events, method = "Effective actors", acled_dataframe = F)$eff_actors)
```

To the eye, `df` is nothing but a heavily concentrated dataset, with 80% of events controlled by actor1, yet the concentration is only 0.66. Where as the __Inversed Simpson Index__ shows us that there is only 1.5 effective actors. 

The divergency surrounds what each method rewards more. The HHI focuses on how "wide" the distribution is (how many actors are present), where the ISI focuses on how "tall" the distribution is (how many events per actors there is). Often times you will require both to get a more comprehensive picture of the structure of the dataset. 

# EDA with acledR - `acled_report_*`

_ Purposefully incomplete_ 
